{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "query-anime-list.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1EMiYKh61nZ8VL6-Xx2J_4KkPVeWDOiFd",
      "authorship_tag": "ABX9TyO1LuFs5tBZGlyMxQK7OsNi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/exglade/query-anime/blob/main/query_anime_list.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ujTGCy3_Znjk"
      },
      "source": [
        "# Query Anime List"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7E31EQHhGuL"
      },
      "source": [
        "## Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRU8lAAchGb9"
      },
      "source": [
        "I have a spreadsheet of anime list with following columns:\n",
        "\n",
        "- **Parent**: The anime's parent title.\n",
        "- **Title**: The full anime title.\n",
        "- **Genre**: The anime genre (according to MyAnimeList).\n",
        "- **Season**: The xth season of the anime. Non-season type: OVA, Movie, ONA, Special.\n",
        "- **Total Episodes**: The total number of episodes that the anime has.\n",
        "- **Date of Release**: The date when the anime start airing.\n",
        "- **Date of Completion**: The date when the anime finishes airing.\n",
        "- **Status**: The airing status of the anime: Unreleased, Ongoing, Released.\n",
        "- **Last**: The last episode I've watched.\n",
        "- **Score**: My personal rating of the anime on a scale of 0-5.\n",
        "\n",
        "There is a list of Anime tabs stored in OneTab. The list can be exported from OneTab into text. Examples below:\n",
        "\n",
        "```text\n",
        "https://www.microsoft.com/design/fluent/#/ | Microsoft Design\n",
        "https://medium.com/microsoft-design/designing-for-power-simplicity-9cddec615567 | Designing for Power and Simplicity - Microsoft Design - Medium\n",
        "...\n",
        "```\n",
        "\n",
        "After clean-up, there are 150 anime in the list. Performing query on anime one by one and copy the information would take hours.\n",
        "\n",
        "There has to be a better way so it would be easier for me in future too! üòÅ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GF_XuRFbhGK4"
      },
      "source": [
        "## Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C-mnSIAZtUB"
      },
      "source": [
        "1. Data: Extract, Transform, Load the anime list.\n",
        "2. Search for anime by name.\n",
        "3. Map anime to anime list's identifier.\n",
        "4. Fetch Anime details.\n",
        "5. Export into spreadsheet. üéâ\n",
        "\n",
        "### API\n",
        "- [MyAnimeList](https://myanimelist.net/) - [v2](https://myanimelist.net/apiconfig/references/api/v2) | [Authorisation guide](https://myanimelist.net/blog.php?eid=835707)\n",
        "- [AniList](https://anilist.co/) - [v2](https://anilist.gitbook.io/anilist-apiv2-docs/)\n",
        "- [Jikan](https://jikan.moe/) - [v3](https://jikan.docs.apiary.io/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49_AluC3ZGBt"
      },
      "source": [
        "# Data: Extract, Transform, Load"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ehf-5WeZF9K"
      },
      "source": [
        "1. Export the list of tabs using OneTab export\n",
        "2. For each line, filter away non-relevant lines and parse the data.\n",
        "3. Save the parsed into CSV for later use.\n",
        "\n",
        "**Anime record columns:**\n",
        "- Anime name\n",
        "- Episode that I watched until\n",
        "- Full URL\n",
        "- Page title\n",
        "- Website"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGC9NalNZR0M"
      },
      "source": [
        "# https://colab.research.google.com/notebooks/io.ipynb#scrollTo=u22w3BFiOveA\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#drive.flush_and_unmount()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhyVyT-eRErf"
      },
      "source": [
        "# !cat '/content/drive/MyDrive/Colab Notebooks/mal-anime-query/Data/onetab-list.txt'\n",
        "data_dir = '/content/drive/MyDrive/Colab Notebooks/mal-anime-query/Data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VHyq7tXeQSW"
      },
      "source": [
        "import re\n",
        "import uuid\n",
        "\n",
        "class AnimeRecord:\n",
        "  def __init__(self, url, page_title, name, episode, website, id):\n",
        "    self.id = id\n",
        "    self.page_title = page_title\n",
        "    self.url = url\n",
        "    self.name = name\n",
        "    self.episode = episode\n",
        "    self.website = website\n",
        "\n",
        "  @classmethod\n",
        "  def construct(self, url, page_title):\n",
        "    id = uuid.uuid4()\n",
        "    name = ''\n",
        "    episode = 0\n",
        "    website = ''\n",
        "\n",
        "    clean_page_title = page_title\n",
        "    match = re.search('Episode (?P<episode>[\\d]+)', page_title)\n",
        "    if match:\n",
        "        episode = match.group('episode').strip()\n",
        "        clean_page_title = page_title[:match.span()[0]]\n",
        "\n",
        "    match = re.search('(Watch )*(?P<title>.*)', clean_page_title)\n",
        "    if match:\n",
        "      name = match.group('title').strip()\n",
        "\n",
        "    match = re.search('(http[s]*):\\/\\/([\\w\\d]+\\.)?(?P<site>[\\w\\d]+\\.[\\w]+)\\/.*', url)\n",
        "    if match:\n",
        "      website = match.group('site').strip()\n",
        "\n",
        "    return self(url=url, page_title=page_title, id=id, name=name, episode=episode, website=website)\n",
        "\n",
        "  @classmethod\n",
        "  def from_dict(self, dict):\n",
        "    return self(url=dict['url'], page_title=dict['page_title'], id=dict['id'], name=dict['name'], episode=dict['episode'], website=dict['website'])\n",
        "\n",
        "  def __str__(self):\n",
        "    return \"Name='%s', Episode='%s', Website='%s'\" % (self.name, self.episode, self.website)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHGqvGBNUfMS"
      },
      "source": [
        "import re\n",
        "\n",
        "input_file = data_dir + 'onetab-raw2.txt'\n",
        "\n",
        "animes = []\n",
        "i = 0\n",
        "with open(input_file, 'r') as f:\n",
        "  lines = f.readlines()\n",
        "\n",
        "  for line in lines:\n",
        "    # Remove possible irrelevant lines\n",
        "    if not re.match('http[s]?:\\/\\/.*anime.*\\.[a-z]+\\/.* \\|', line): # Assumption all anime sites has 'anime' in url\n",
        "      continue\n",
        "    if 'myanimelist' in line: # Ignore myanimelist\n",
        "      continue\n",
        "    if not len(line.strip()):\n",
        "      continue\n",
        "\n",
        "    separator_index = line.index('|')\n",
        "    page_url = line[0:separator_index].strip()\n",
        "    page_title = line[separator_index+1:].strip()\n",
        "\n",
        "    anime = AnimeRecord.construct(page_url, page_title)\n",
        "    animes.append(anime)\n",
        "    \n",
        "    i += 1\n",
        "    print('[%d]%s' % (i, anime))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlD5IlbBGM67"
      },
      "source": [
        "# Clean up duplicates\n",
        "\n",
        "animes_dupe_dict = {}\n",
        "for anime in animes:\n",
        "  if anime.name not in animes_dupe_dict or animes_dupe_dict[anime.name].episode < anime.episode:\n",
        "      animes_dupe_dict[anime.name] = anime\n",
        "\n",
        "i = 0\n",
        "animes = animes_dupe_dict.values()\n",
        "for anime in animes:\n",
        "  i += 1\n",
        "  print('[%d]%s' % (i, anime))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMYDqzqbVQ_y"
      },
      "source": [
        "print('Possible dirty records:')\n",
        "\n",
        "for anime in animes:\n",
        "  if anime.episode == 0:\n",
        "    print(anime)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTzepNA8Sinh"
      },
      "source": [
        "# Manual clean data\n",
        "\n",
        "cleaner_map = {\n",
        "    'Wonder Egg Priority English Subbed Online Free': 'Wonder Egg Priority',\n",
        "    'Jujutsu Kaisen (TV) English Subbed Online Free': 'Jujutsu Kaisen (TV)',\n",
        "    'Sword Art Online: Alicization - War of Underworld Anime English Subbed in HD for Free on Animefreak.TV': 'Sword Art Online: Alicization - War of Underworld',\n",
        "    'Kekkai Sensen: Ousama no Restaurant no Ousama OVA Online | English Dubbed-Subbed Episodes': 'Kekkai Sensen: Ousama no Restaurant no Ousama OVA',\n",
        "    'Nanatsu no Taizai OVA 2 Online | English Dubbed-Subbed Episodes': 'Nanatsu no Taizai OVA'\n",
        "}\n",
        "\n",
        "for anime in animes:\n",
        "  if anime.name in cleaner_map:\n",
        "    print('Changing \"%s\" to \"%s\"' % (anime.name, cleaner_map[anime.name]))\n",
        "    anime.name = cleaner_map[anime.name]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OOAUYTgo3xb"
      },
      "source": [
        "## Saving parsed data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zx59LQGpKyt"
      },
      "source": [
        "Keep the parsed data into persistent file to cache the data for future use.\n",
        "\n",
        "This also allows us to clean the data before the next step. It's possible that the data is dirty because page title is not standardise to any specific format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y1xctm-Uxy4"
      },
      "source": [
        "import csv\n",
        "\n",
        "output_file = data_dir + 'output.csv'\n",
        "with open(output_file, mode='w') as csv_file:\n",
        "    fieldnames = ['id', 'name', 'episode', 'website', 'page_title', 'url']\n",
        "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "\n",
        "    writer.writeheader()\n",
        "    for anime in animes:\n",
        "      writer.writerow(vars(anime))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxlCm3JrTy9g"
      },
      "source": [
        "import csv\n",
        "\n",
        "i = 0\n",
        "animes_file = data_dir + 'output.csv'\n",
        "with open(animes_file, mode='r') as csv_file:\n",
        "  reader = csv.DictReader(csv_file)\n",
        "  animes = []\n",
        "  for row in reader:\n",
        "    anime = AnimeRecord.from_dict(row)\n",
        "    animes.append(anime)\n",
        "\n",
        "    i += 1\n",
        "    print('[%d]%s' % (i, anime))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCiXdJ9B5iJq"
      },
      "source": [
        "# Connect to MAL & Query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7JGMuXz5pQm"
      },
      "source": [
        "!pip install jikanpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azKSqVw9-zJ-"
      },
      "source": [
        "## API References\n",
        "\n",
        "This section describes some [JikanPy API](https://jikanpy.readthedocs.io/en/latest/) that I would be using. [Jikan's official API documentation](https://jikan.docs.apiary.io/) contains more parameters that may be inserted into JikanPy.\n",
        "\n",
        "[`jikan.anime()`](https://jikanpy.readthedocs.io/en/latest/#jikanpy.Jikan.anime) gets information on an anime.\n",
        "\n",
        "Response sample:\n",
        "```json\n",
        "{'request_hash': 'request:anime:047ce4420fa843606934309866d292274c149a83', 'request_cached': True, 'request_cache_expiry': 79963, 'mal_id': 457, 'url': 'https://myanimelist.net/anime/457/Mushishi', 'image_url': 'https://cdn.myanimelist.net/images/anime/2/73862.jpg', 'trailer_url': 'https://www.youtube.com/embed/h371H0KIuPo?enablejsapi=1&wmode=opaque&autoplay=1', 'title': 'Mushishi', 'title_english': 'Mushi-Shi', 'title_japanese': 'Ëü≤Â∏´', 'title_synonyms': [], 'type': 'TV', 'source': 'Manga', 'episodes': 26, 'status': 'Finished Airing', 'airing': False, 'aired': {'from': '2005-10-23T00:00:00+00:00', 'to': '2006-06-19T00:00:00+00:00', 'prop': {'from': {'day': 23, 'month': 10, 'year': 2005}, 'to': {'day': 19, 'month': 6, 'year': 2006}}, 'string': 'Oct 23, 2005 to Jun 19, 2006'}, 'duration': '25 min per ep', 'rating': 'PG-13 - Teens 13 or older', 'score': 8.69, 'scored_by': 208969, 'rank': 49, 'popularity': 171, 'members': 644011, 'favorites': 23588, 'synopsis': '\"Mushi\": the most basic forms of life in the world. They exist without any goals or purposes aside from simply \"being.\" They are beyond the shackles of the words \"good\" and \"evil.\" Mushi can exist in countless forms and are capable of mimicking things from the natural world such as plants, diseases, and even phenomena like rainbows. This is, however, just a vague definition of these entities that inhabit the vibrant world of Mushishi, as to even call them a form of life would be an oversimplification. Detailed information on Mushi is scarce because the majority of humans are unaware of their existence. So what are Mushi and why do they exist? This is the question that a \"Mushishi,\" Ginko, ponders constantly. Mushishi are those who research Mushi in hopes of understanding their place in the world\\'s hierarchy of life. Ginko chases rumors of occurrences that could be tied to Mushi, all for the sake of finding an answer. It could, after all, lead to the meaning of life itself. [Written by MAL Rewrite]', 'background': None, 'premiered': 'Fall 2005', 'broadcast': 'Sundays at 03:40 (JST)', 'related': {'Adaptation': [{'mal_id': 418, 'type': 'manga', 'name': 'Mushishi', 'url': 'https://myanimelist.net/manga/418/Mushishi'}], 'Sequel': [{'mal_id': 21329, 'type': 'anime', 'name': 'Mushishi: Hihamukage', 'url': 'https://myanimelist.net/anime/21329/Mushishi__Hihamukage'}, {'mal_id': 21939, 'type': 'anime', 'name': 'Mushishi Zoku Shou', 'url': 'https://myanimelist.net/anime/21939/Mushishi_Zoku_Shou'}], 'Summary': [{'mal_id': 39738, 'type': 'anime', 'name': 'Mushishi Recap', 'url': 'https://myanimelist.net/anime/39738/Mushishi_Recap'}]}, 'producers': [{'mal_id': 52, 'type': 'anime', 'name': 'Avex Entertainment', 'url': 'https://myanimelist.net/anime/producer/52/Avex_Entertainment'}, {'mal_id': 82, 'type': 'anime', 'name': 'Marvelous', 'url': 'https://myanimelist.net/anime/producer/82/Marvelous'}, {'mal_id': 147, 'type': 'anime', 'name': 'SKY Perfect Well Think', 'url': 'https://myanimelist.net/anime/producer/147/SKY_Perfect_Well_Think'}, {'mal_id': 711, 'type': 'anime', 'name': 'Delfi Sound', 'url': 'https://myanimelist.net/anime/producer/711/Delfi_Sound'}], 'licensors': [{'mal_id': 102, 'type': 'anime', 'name': 'Funimation', 'url': 'https://myanimelist.net/anime/producer/102/Funimation'}], 'studios': [{'mal_id': 8, 'type': 'anime', 'name': 'Artland', 'url': 'https://myanimelist.net/anime/producer/8/Artland'}], 'genres': [{'mal_id': 2, 'type': 'anime', 'name': 'Adventure', 'url': 'https://myanimelist.net/anime/genre/2/Adventure'}, {'mal_id': 36, 'type': 'anime', 'name': 'Slice of Life', 'url': 'https://myanimelist.net/anime/genre/36/Slice_of_Life'}, {'mal_id': 7, 'type': 'anime', 'name': 'Mystery', 'url': 'https://myanimelist.net/anime/genre/7/Mystery'}, {'mal_id': 13, 'type': 'anime', 'name': 'Historical', 'url': 'https://myanimelist.net/anime/genre/13/Historical'}, {'mal_id': 37, 'type': 'anime', 'name': 'Supernatural', 'url': 'https://myanimelist.net/anime/genre/37/Supernatural'}, {'mal_id': 10, 'type': 'anime', 'name': 'Fantasy', 'url': 'https://myanimelist.net/anime/genre/10/Fantasy'}, {'mal_id': 42, 'type': 'anime', 'name': 'Seinen', 'url': 'https://myanimelist.net/anime/genre/42/Seinen'}], 'opening_themes': ['\"The Sore Feet Song\" by Ally Kerr'], 'ending_themes': ['#01: \"Midori no Za\" (Á∑ë„ÅÆÂ∫ß) by Masuda Toshio (ep 1)', '#02: \"Mabuta no Hikari\" (Áûº„ÅÆÂÖâ) by Masuda Toshio (ep 2)', '#03: \"Yawarakai Kaku\" (Êüî„Çâ„Åã„ÅÑËßí) by Masuda Toshio (ep 3)', '#04: \"Makura Kouji\" (ÊûïÂ∞èË∑Ø ) by Masuda Toshio (ep 4)', '#05: \"Tabi wo Suru Numa\" (ÊóÖ„Çí„Åô„ÇãÊ≤º) by Masuda Toshio (ep 5)', '#06: \"Tsuyu wo Suu Mure\" (Èú≤„ÇíÂê∏„ÅÜÁæ§„Çå) by Masuda Toshio (ep 6)', '#07: \"Ame ga Kuru Niji ga Tatsu\" (Èõ®„Åå„Åè„ÇãËôπ„Åå„Åü„Å§) by Masuda Toshio (ep 7)', '#08: \"Unasaka Yori\" (Êµ∑Â¢É„Çà„Çä)  by Masuda Toshio (ep 8)', '#09: \"Omoi Mi\" (Èáç„ÅÑÂÆü) by Masuda Toshio (ep 9)', '#10: \"Suzuri ni Sumu Shiro\" (Á°Ø„Å´Ê£≤„ÇÄÁôΩ) by Masuda Toshio (ep 10)', '#11: \"Yama Nemuru\" („ÇÑ„Åæ„Å≠„ÇÄ„Çã) by Masuda Toshio (ep 11)', '#12: \"Sugame no Sakana\" (Áúá„ÅÆÈ≠ö) by Masuda Toshio (ep 12)', '#13: \"Hitoyobashi\" (‰∏ÄÂ§úÊ©ã) by Masuda Toshio (ep 13)', '#14: \"Kago no Naka\" (Á±†„ÅÆ„Å™„Åã) by Masuda Toshio (ep 14)', '#15: \"Haru to Usobuko\" (Êò•„Å®ÂòØ„Åè) by Masuda Toshio (ep 15)', '#16: \"Akatsuki no Hebi\" (ÊöÅ„ÅÆËõá) by Masuda Toshio (ep 16)', '#17: \"Uromayutori\" (ËôöÁπ≠Âèñ„Çä) by Masuda Toshio (ep 17)', '#18: \"Yama Daku Koromo\" (Â±±Êä±„ÅèË°£) by Masuda Toshio (ep 18)', '#19: \"Tenpen no Ito\" (Â§©Ëæ∫„ÅÆÁ≥∏) by Masuda Toshio (ep 19)', '#20: \"Fude no Umi\" (Á≠Ü„ÅÆÊµ∑) by Masuda Toshio (ep 20)', '#21: \"Wataboshi\" (Á∂øËÉûÂ≠ê) by Masuda Toshio (ep 21)', '#22: \"Okitsu Miya\" (Ê≤ñ„Å§ÂÆÆ) by Masuda Toshio (ep 22)', '#23: \"Sabi no Naku Koe\" (ÈåÜ„ÅÆÈ≥¥„ÅèËÅ≤) by Masuda Toshio (ep 23)', '#24: \"Kagarinokou\" (ÁØùÈáéË°å) by Masuda Toshio (ep 24)', '#25: \"Ganpuku Ganka\" (ÁúºÁ¶èÁúºÁ¶ç) by Masuda Toshio (ep 25)', '#26: \"Kusa wo Fumu Oto\" (Ëçâ„ÇíË∏è„ÇÄÈü≥) by Masuda Toshio (ep 26)'], 'jikan_url': 'https://api.jikan.moe/v3/anime/457', 'headers': {'Server': 'nginx/1.18.0 (Ubuntu)', 'Date': 'Wed, 21 Apr 2021 05:34:02 GMT', 'Content-Type': 'application/json', 'Content-Length': '2451', 'Connection': 'keep-alive', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Methods': '*', 'Cache-Control': 'private, must-revalidate', 'ETag': '\"267b5262eebb7ade477a0f5c5590e1a2\"', 'X-Request-Hash': 'request:anime:047ce4420fa843606934309866d292274c149a83', 'X-Request-Cached': '1', 'X-Request-Cache-Ttl': '79963', 'Expires': 'Thu, 22 Apr 2021 03:46:45 GMT', 'Content-Encoding': 'gzip', 'Vary': 'Accept-Encoding', 'X-Cache-Status': 'MISS'}}\n",
        "```\n",
        "\n",
        "[`jikan.search()`](https://jikanpy.readthedocs.io/en/latest/#jikanpy.Jikan.search) searches for a query on MyAnimeList.\n",
        "\n",
        "Response sample:\n",
        "```json\n",
        "{'request_hash': 'request:search:5fec258ddd152243fe19deb2c52974a575c0a888', 'request_cached': False, 'request_cache_expiry': 432000, 'results': [{'mal_id': 38000, 'url': 'https://myanimelist.net/anime/38000/Kimetsu_no_Yaiba', 'image_url': 'https://cdn.myanimelist.net/images/anime/1286/99889.jpg?s=e497d08bef31ae412e314b90a54acfda', 'title': 'Kimetsu no Yaiba', 'airing': False, 'synopsis': \"Ever since the death of his father, the burden of supporting the family has fallen upon Tanjirou Kamado's shoulders. Though living impoverished on a remote mountain, the Kamado family are able to enjo...\", 'type': 'TV', 'episodes': 26, 'score': 8.6, 'start_date': '2019-04-06T00:00:00+00:00', 'end_date': '2019-09-28T00:00:00+00:00', 'members': 1637158, 'rated': 'R'}, {'mal_id': 47778, 'url': 'https://myanimelist.net/anime/47778/Kimetsu_no_Yaiba__Yuukaku-hen', 'image_url': 'https://cdn.myanimelist.net/images/anime/1338/111945.jpg?s=8ad61bdf543abb9291fe2eeb52a2cb26', 'title': 'Kimetsu no Yaiba: Yuukaku-hen', 'airing': False, 'synopsis': 'Tanjiro, Zenitsu and Inosuke aided by the Sound Hashira Tengen Uzui travel to Yoshiwara red light district to hunt down a demon that has been terrorizing the town.', 'type': 'TV', 'episodes': 0, 'score': 0, 'start_date': None, 'end_date': None, 'members': 95360, 'rated': 'R'}, {'mal_id': 40456, 'url': 'https://myanimelist.net/anime/40456/Kimetsu_no_Yaiba_Movie__Mugen_Ressha-hen', 'image_url': 'https://cdn.myanimelist.net/images/anime/1704/106947.jpg?s=685b7fa652f5b3df29bd20fc2c8cb32e', 'title': 'Kimetsu no Yaiba Movie: Mugen Ressha-hen', 'airing': False, 'synopsis': \"After a string of mysterious disappearances begin to plague a train, the Demon Slayer Corps' multiple attempts to remedy the problem prove fruitless. To prevent further casualties, the flame pillar, K...\", 'type': 'Movie', 'episodes': 1, 'score': 8.71, 'start_date': '2020-10-16T00:00:00+00:00', 'end_date': '2020-10-16T00:00:00+00:00', 'members': 408674, 'rated': 'R'}], 'last_page': 20, 'jikan_url': 'https://api.jikan.moe/v3/search/anime?q=Kimetsu no Yaiba&limit=3', 'headers': {'Server': 'nginx/1.18.0 (Ubuntu)', 'Date': 'Wed, 21 Apr 2021 06:00:25 GMT', 'Content-Type': 'application/json', 'Content-Length': '914', 'Connection': 'keep-alive', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Methods': '*', 'Cache-Control': 'private, must-revalidate', 'ETag': '\"a3dd9f1d6f98bd837cfe2b4ab918847d\"', 'X-Request-Hash': 'request:search:5fec258ddd152243fe19deb2c52974a575c0a888', 'X-Request-Cached': '', 'X-Request-Cache-Ttl': '432000', 'Expires': 'Mon, 26 Apr 2021 06:00:25 GMT', 'Content-Encoding': 'gzip', 'Vary': 'Accept-Encoding', 'X-Cache-Status': 'MISS'}}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUHbmliq5pKz"
      },
      "source": [
        "import time\n",
        "from jikanpy import Jikan\n",
        "from jikanpy.exceptions import APIException\n",
        "jikan = Jikan()\n",
        "\n",
        "# https://jikanpy.readthedocs.io/en/latest/\n",
        "# time.sleep(4) # Remember to sleep 4 seconds between requests\n",
        "\n",
        "search_results = {}\n",
        "for anime in animes:\n",
        "  try:\n",
        "    result = jikan.search('anime', anime.name, parameters={ 'limit': 3 })\n",
        "    search_results[anime.id] = result\n",
        "    print('Searched \"%s\", found %d result(s)' % (anime.name, len(result['results'])))\n",
        "  except APIException as e:\n",
        "    print('APIException: %s' % e)\n",
        "  \n",
        "  time.sleep(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7rBl29I_6NX"
      },
      "source": [
        "import json\n",
        "\n",
        "search_json_file = data_dir + 'search_results.json'\n",
        "\n",
        "search_json = json.dumps(search_results, indent=2)\n",
        "#print(search_json)\n",
        "\n",
        "with open(search_json_file, mode='w') as f:\n",
        "  f.write(search_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKRe_-PhpBTu"
      },
      "source": [
        "import json\n",
        "\n",
        "search_json_file = data_dir + 'search_results.json'\n",
        "\n",
        "with open(search_json_file, mode='r') as f:\n",
        "  search_results = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU9zzUYGqBAd"
      },
      "source": [
        "# Map Anime to MAL Id\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojlpBCHfqY0k"
      },
      "source": [
        "Search with name doesn't guarantee the accuracy. Therefore, this section will check if the anime name matches the first result using a strict string match.\n",
        "\n",
        "- If the names match, the result is correct.\n",
        "- If the names doesn't match, I manually check subsequent result match.1\n",
        "- If none match, a manual search is required."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5Mn3cmMqG3K"
      },
      "source": [
        "i = 0\n",
        "\n",
        "anime_dicts = []\n",
        "for anime in animes:\n",
        "  search_result = search_results[anime.id]\n",
        "\n",
        "  matching_result = search_result['results'][0]\n",
        "  for result in search_result['results']:\n",
        "    if result['title'] == anime.name:\n",
        "      matching_result = result\n",
        "\n",
        "  anime_dict = {\n",
        "      'anime_id': anime.id,\n",
        "      'anime_name': anime.name,\n",
        "      'mal_id': matching_result['mal_id'],\n",
        "      'mal_name': matching_result['title']\n",
        "  }\n",
        "  anime_dicts.append(anime_dict)\n",
        "\n",
        "  i += 1\n",
        "  print_text = '[%d]%s -> %s'\n",
        "  if anime_dict['anime_name'] != anime_dict['mal_name']:\n",
        "    print_text = '\\033[31;47m' + print_text + '\\033[0m' # https://en.wikipedia.org/wiki/ANSI_escape_code#SGR_(Select_Graphic_Rendition)_parameters\n",
        "\n",
        "  print(print_text % (i, anime_dict['anime_name'], anime_dict['mal_name']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On1NUNuXhZGN"
      },
      "source": [
        "import csv\n",
        "\n",
        "output_file = data_dir + 'anime_mapping.csv'\n",
        "with open(output_file, mode='w') as csv_file:\n",
        "    fieldnames = ['anime_id', 'anime_name', 'mal_id', 'mal_name']\n",
        "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "\n",
        "    writer.writeheader()\n",
        "    for anime_dict in anime_dicts:\n",
        "      writer.writerow(anime_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6BRkPsycQ5i"
      },
      "source": [
        "‚ö† Manually clean the anime mapping."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_s2ea4FqC4v"
      },
      "source": [
        "import csv\n",
        "\n",
        "animes_file = data_dir + 'anime_mapping_cleaned2.csv'\n",
        "with open(animes_file, mode='r') as csv_file:\n",
        "  reader = csv.DictReader(csv_file)\n",
        "  anime_dicts = []\n",
        "  for row in reader:\n",
        "    anime_dicts.append(row)\n",
        "\n",
        "    i += 1\n",
        "    print('[%d]%s' % (i, row))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JK2hR4VDr9Ak"
      },
      "source": [
        "# Fetch Anime Details\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEUnbznor5yf"
      },
      "source": [
        "- **Title**: The full anime title.\n",
        "- **Genre**: The anime genre (according to MyAnimeList).\n",
        "- **Season**: The xth season of the anime. Non-season type: OVA, Movie, ONA, Special.\n",
        "- **Total Episodes**: The total number of episodes that the anime has.\n",
        "- **Date of Release**: The date when the anime start airing.\n",
        "- **Date of Completion**: The date when the anime finishes airing.\n",
        "- **Status**: The airing status of the anime: Unreleased, Ongoing, Released.\n",
        "- **Last**: The last episode I've watched."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vU2_cIXr8Sg"
      },
      "source": [
        "import time\n",
        "from jikanpy import Jikan\n",
        "from jikanpy.exceptions import APIException\n",
        "jikan = Jikan()\n",
        "\n",
        "# https://jikanpy.readthedocs.io/en/latest/\n",
        "# time.sleep(4) # Remember to sleep 4 seconds between requests\n",
        "\n",
        "anime_results = {}\n",
        "i = 0\n",
        "for anime_dict in anime_dicts:\n",
        "  try:\n",
        "    result = jikan.anime(anime_dict['mal_id'])\n",
        "    anime_results[anime_dict['anime_id']] = result\n",
        "    i += 1\n",
        "    print('[%d]Get anime [%s -> %s] \"%s\"' % (i, anime_dict['anime_id'], anime_dict['mal_id'], anime_dict['anime_name']))\n",
        "  except APIException as e:\n",
        "    print('APIException: %s' % e)\n",
        "  \n",
        "  time.sleep(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7TO_2GeyWVk"
      },
      "source": [
        "import json\n",
        "\n",
        "anime_json_file = data_dir + 'anime_results.json'\n",
        "\n",
        "anime_json = json.dumps(anime_results, indent=2)\n",
        "#print(search_json)\n",
        "\n",
        "with open(anime_json_file, mode='w') as f:\n",
        "  f.write(anime_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_mZAYMgt45B"
      },
      "source": [
        "import json\n",
        "\n",
        "anime_json_file = data_dir + 'anime_results.json'\n",
        "\n",
        "with open(anime_json_file, mode='r') as f:\n",
        "  anime_results = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEze-iLwwIw0"
      },
      "source": [
        "import csv\n",
        "\n",
        "final_records = []\n",
        "\n",
        "for anime in animes:\n",
        "  result = anime_results[anime.id]\n",
        "\n",
        "  final_record = {\n",
        "      'title': result['title'],\n",
        "      'genre': ', '.join(genre['name'] for genre in result['genres']),\n",
        "      'total_episode': result['episodes'],\n",
        "      'release_date': result['aired']['from'],\n",
        "      'completion_date': result['aired']['to'],\n",
        "      'last_watched': anime.episode\n",
        "  }\n",
        "  final_records.append(final_record)\n",
        "  print(final_record)\n",
        "\n",
        "final_output_file = data_dir + 'final_output.csv'\n",
        "with open(final_output_file, mode='w') as csv_file:\n",
        "  fieldnames = final_records[0].keys()\n",
        "  writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
        "\n",
        "  writer.writeheader()\n",
        "  for final_record in final_records:\n",
        "    writer.writerow(final_record)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}